apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: spark-operator
  namespace: argocd
  finalizers:
    - resources-finalizer.argocd.argoproj.io
spec:
  project: default
  source:
    repoURL: https://googlecloudplatform.github.io/spark-on-k8s-operator
    chart: spark-operator
    targetRevision: 1.1.27
    helm:
      values: |
        image:
          repository: gcr.io/spark-operator/spark-operator
          tag: v1beta2-1.3.8-3.1.1
        
        sparkJobNamespace: spark-jobs
        
        webhook:
          enable: true
          port: 8080
        
        metrics:
          enable: true
          port: 10254
          endpoint: /metrics
          portName: metrics
        
        controllerThreads: 10
        resyncInterval: 30
        
        resources:
          requests:
            cpu: 100m
            memory: 300Mi
          limits:
            cpu: 500m
            memory: 512Mi
        
        nodeSelector: {}
        
        tolerations: []
        
        affinity: {}
        
        serviceAccount:
          create: true
          name: spark-operator
        
        rbac:
          create: true
          createClusterRole: true
          createRole: true
        
        batchScheduler:
          enable: false
        
        podSecurityPolicy:
          enable: false
        
        istio:
          enabled: false
        
        sparkApplications:
          - name: spark-pi
            namespace: spark-jobs
            spec:
              type: Scala
              mode: cluster
              image: gcr.io/spark-operator/spark:v3.1.1
              imagePullPolicy: Always
              mainClass: org.apache.spark.examples.SparkPi
              mainApplicationFile: local:///opt/spark/examples/jars/spark-examples_2.12-3.1.1.jar
              arguments:
                - "10"
              sparkVersion: 3.1.1
              restartPolicy:
                type: Never
              driver:
                cores: 1
                coreLimit: 1200m
                memory: 512m
                labels:
                  version: 3.1.1
                serviceAccount: spark-operator-spark
              executor:
                cores: 1
                instances: 1
                memory: 512m
                labels:
                  version: 3.1.1
        
        sparkHistoryServer:
          enable: true
          image:
            repository: gcr.io/spark-operator/spark
            tag: v3.1.1
          resources:
            requests:
              cpu: 100m
              memory: 256Mi
            limits:
              cpu: 200m
              memory: 512Mi
          service:
            type: ClusterIP
            port: 18080
          persistence:
            enabled: true
            size: 10Gi
            storageClass: ""
          s3:
            enabled: true
            endpoint: http://minio.minio.svc.cluster.local:9000
            accessKeyId: minioadmin
            secretAccessKey: minioadmin123
            bucket: spark-history
            region: us-east-1
            pathStyleAccess: true
            sslEnabled: false
  destination:
    server: https://kubernetes.default.svc
    namespace: spark-operator
  syncPolicy:
    automated:
      prune: true
      selfHeal: true
    syncOptions:
      - CreateNamespace=true
      - PrunePropagationPolicy=foreground
      - PruneLast=true
    retry:
      limit: 5
      backoff:
        duration: 5s
        factor: 2
        maxDuration: 3m

